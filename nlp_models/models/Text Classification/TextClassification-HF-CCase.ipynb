{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.3.0)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.9.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (5.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2022.11.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.3)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import evaluate\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the CCase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>customerccase_id</th>\n",
       "      <th>ccases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXXX0005</td>\n",
       "      <td>AAAA1114</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000048\"},\"filename\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XXXX0005</td>\n",
       "      <td>AAAA1115</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000021\"},\"channel\":{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XXXX0005</td>\n",
       "      <td>AAAA1116</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000044\"},\"filename\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XXXX0004</td>\n",
       "      <td>AAAA1116</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000045\"},\"filename\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XXXX0004</td>\n",
       "      <td>AAAA1117</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000047\"},\"filename\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id customerccase_id  \\\n",
       "0  XXXX0005         AAAA1114   \n",
       "1  XXXX0005         AAAA1115   \n",
       "2  XXXX0005         AAAA1116   \n",
       "3  XXXX0004         AAAA1116   \n",
       "4  XXXX0004         AAAA1117   \n",
       "\n",
       "                                              ccases  \n",
       "0  [{\"M\":{\"ccase_id\":{\"S\":\"00000048\"},\"filename\":...  \n",
       "1  [{\"M\":{\"ccase_id\":{\"S\":\"00000021\"},\"channel\":{...  \n",
       "2  [{\"M\":{\"ccase_id\":{\"S\":\"00000044\"},\"filename\":...  \n",
       "3  [{\"M\":{\"ccase_id\":{\"S\":\"00000045\"},\"filename\":...  \n",
       "4  [{\"M\":{\"ccase_id\":{\"S\":\"00000047\"},\"filename\":...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/root/nlp-coe/nltk_data/corpora/ccase/')\n",
    "df_ccase=pd.read_csv('results.csv')\n",
    "print(df_ccase.shape)\n",
    "df_ccase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'S': 'Jessica speaks to Jessica about how she got her iPad back online'},\n",
       " {'S': 'Jessica says her iPad is connected automatically through WiFi Jessica: \"I think Google stuff again'},\n",
       " {'S': \"This is amazing I think Google things again That's great to hear\"},\n",
       " {'S': 'Is there anything else I can help you with today? Nope'},\n",
       " {'S': 'Could I ask how satisfied you were with a resolution today? Very satisfied Very satisfied, very satisfied'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "json.loads(df_ccase['ccases'][0])[0]['M']['data']['M']['keyphrases']['L'][0]['L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_actions = [0, 1, 2]\n",
    "# next_actions = [\"DO NOTHING\", \"RECOMMEND PROMOTION\", \"PROVIDE REFUND\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ccase):\n",
    "    d = json.loads(ccase)[0]\n",
    "    output = '. '.join(a['S'] for a in d['M']['data']['M']['keyphrases']['L'][0]['L'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccase['summary'] = df_ccase['ccases'].apply(lambda x: prepare(x))\n",
    "df_ccase['class_'] = random.choices(next_actions, k=len(df_ccase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>customerccase_id</th>\n",
       "      <th>ccases</th>\n",
       "      <th>summary</th>\n",
       "      <th>class_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XXXX0005</td>\n",
       "      <td>AAAA1114</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000048\"},\"filename\":...</td>\n",
       "      <td>Jessica speaks to Jessica about how she got he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XXXX0005</td>\n",
       "      <td>AAAA1115</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000021\"},\"channel\":{...</td>\n",
       "      <td>Victoria Broadband has been struggling to find...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XXXX0005</td>\n",
       "      <td>AAAA1116</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000044\"},\"filename\":...</td>\n",
       "      <td>Jessica's iPad is connected automatically for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XXXX0004</td>\n",
       "      <td>AAAA1116</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000045\"},\"filename\":...</td>\n",
       "      <td>Jessicas We're calling you back to formula tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XXXX0004</td>\n",
       "      <td>AAAA1117</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000047\"},\"filename\":...</td>\n",
       "      <td>Jessica's iPad connected automatically for WiF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XXXX0003</td>\n",
       "      <td>AAAA1114</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000010\"},\"channel\":{...</td>\n",
       "      <td>A large wave of orders came in last week So ou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XXXX0002</td>\n",
       "      <td>AAAA1114</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000009\"},\"channel\":{...</td>\n",
       "      <td>The bar code is dru K R U K K , which means \"D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XXXX0002</td>\n",
       "      <td>AAAA1115</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000011\"},\"channel\":{...</td>\n",
       "      <td>There is sometimes and they were saying no co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XXXX0002</td>\n",
       "      <td>AAAA1117</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000017\"},\"channel\":{...</td>\n",
       "      <td>Telefonica's new broadband service has unlimit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XXXX0001</td>\n",
       "      <td>AAAA1114</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000008\"},\"channel\":{...</td>\n",
       "      <td>V voucher for an Apples phone is a voucher for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XXXX0001</td>\n",
       "      <td>AAAA1115</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000012\"},\"channel\":{...</td>\n",
       "      <td>Manager at victoria's broadband says he is hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XXXX0001</td>\n",
       "      <td>AAAA1116</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000015\"},\"channel\":{...</td>\n",
       "      <td>Mrs [PII] was waiting for her call for some ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XXXX0001</td>\n",
       "      <td>AAAA1117</td>\n",
       "      <td>[{\"M\":{\"ccase_id\":{\"S\":\"00000016\"},\"channel\":{...</td>\n",
       "      <td>Telefonica com will pay a direct debit at the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agent_id customerccase_id  \\\n",
       "0   XXXX0005         AAAA1114   \n",
       "1   XXXX0005         AAAA1115   \n",
       "2   XXXX0005         AAAA1116   \n",
       "3   XXXX0004         AAAA1116   \n",
       "4   XXXX0004         AAAA1117   \n",
       "5   XXXX0003         AAAA1114   \n",
       "6   XXXX0002         AAAA1114   \n",
       "7   XXXX0002         AAAA1115   \n",
       "8   XXXX0002         AAAA1117   \n",
       "9   XXXX0001         AAAA1114   \n",
       "10  XXXX0001         AAAA1115   \n",
       "11  XXXX0001         AAAA1116   \n",
       "12  XXXX0001         AAAA1117   \n",
       "\n",
       "                                               ccases  \\\n",
       "0   [{\"M\":{\"ccase_id\":{\"S\":\"00000048\"},\"filename\":...   \n",
       "1   [{\"M\":{\"ccase_id\":{\"S\":\"00000021\"},\"channel\":{...   \n",
       "2   [{\"M\":{\"ccase_id\":{\"S\":\"00000044\"},\"filename\":...   \n",
       "3   [{\"M\":{\"ccase_id\":{\"S\":\"00000045\"},\"filename\":...   \n",
       "4   [{\"M\":{\"ccase_id\":{\"S\":\"00000047\"},\"filename\":...   \n",
       "5   [{\"M\":{\"ccase_id\":{\"S\":\"00000010\"},\"channel\":{...   \n",
       "6   [{\"M\":{\"ccase_id\":{\"S\":\"00000009\"},\"channel\":{...   \n",
       "7   [{\"M\":{\"ccase_id\":{\"S\":\"00000011\"},\"channel\":{...   \n",
       "8   [{\"M\":{\"ccase_id\":{\"S\":\"00000017\"},\"channel\":{...   \n",
       "9   [{\"M\":{\"ccase_id\":{\"S\":\"00000008\"},\"channel\":{...   \n",
       "10  [{\"M\":{\"ccase_id\":{\"S\":\"00000012\"},\"channel\":{...   \n",
       "11  [{\"M\":{\"ccase_id\":{\"S\":\"00000015\"},\"channel\":{...   \n",
       "12  [{\"M\":{\"ccase_id\":{\"S\":\"00000016\"},\"channel\":{...   \n",
       "\n",
       "                                              summary  class_  \n",
       "0   Jessica speaks to Jessica about how she got he...       1  \n",
       "1   Victoria Broadband has been struggling to find...       1  \n",
       "2   Jessica's iPad is connected automatically for ...       2  \n",
       "3   Jessicas We're calling you back to formula tha...       0  \n",
       "4   Jessica's iPad connected automatically for WiF...       1  \n",
       "5   A large wave of orders came in last week So ou...       2  \n",
       "6   The bar code is dru K R U K K , which means \"D...       0  \n",
       "7    There is sometimes and they were saying no co...       2  \n",
       "8   Telefonica's new broadband service has unlimit...       0  \n",
       "9   V voucher for an Apples phone is a voucher for...       1  \n",
       "10  Manager at victoria's broadband says he is hav...       0  \n",
       "11  Mrs [PII] was waiting for her call for some ti...       1  \n",
       "12  Telefonica com will pay a direct debit at the ...       0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ccase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training(summary, class_):\n",
    "#     return {'class': class_, 'summary': summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jessica speaks to Jessica about how she got he...\n",
       "1     Victoria Broadband has been struggling to find...\n",
       "2     Jessica's iPad is connected automatically for ...\n",
       "3     Jessicas We're calling you back to formula tha...\n",
       "4     Jessica's iPad connected automatically for WiF...\n",
       "5     A large wave of orders came in last week So ou...\n",
       "6     The bar code is dru K R U K K , which means \"D...\n",
       "7      There is sometimes and they were saying no co...\n",
       "8     Telefonica's new broadband service has unlimit...\n",
       "9     V voucher for an Apples phone is a voucher for...\n",
       "10    Manager at victoria's broadband says he is hav...\n",
       "11    Mrs [PII] was waiting for her call for some ti...\n",
       "12    Telefonica com will pay a direct debit at the ...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ccase.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ccase[\"training\"] = df_ccase.apply(lambda x: training(x.summary, x.class_), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ccase['training'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "df = df_ccase[['summary', 'class_']]\n",
    "df.columns = ['text', \"label\"]\n",
    "\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Jessica speaks to Jessica about how she got her iPad back online. Jessica says her iPad is connected automatically through WiFi Jessica: \"I think Google stuff again. This is amazing I think Google things again That\\'s great to hear. Is there anything else I can help you with today? Nope. Could I ask how satisfied you were with a resolution today? Very satisfied Very satisfied, very satisfied',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", problem_type=\"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0833a33edc3d408eab3ad6627b97e8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ccase_tokenised = dataset.map(preprocess_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 13\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ccase_tokenised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Evaluater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"No further operation needed.\", 1: \"Offer a promotion to the customer.\", 2: \"Apply a discount to the price.\"}\n",
    "label2id = {\"No further operation needed.\": 0, \"Offer a promotion to the customer.\": 1, \"Apply a discount to the price.\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 13\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13\n",
      "  Number of trainable parameters = 66955779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.033400</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to my_awesome_model_new/checkpoint-13\n",
      "Configuration saved in my_awesome_model_new/checkpoint-13/config.json\n",
      "Model weights saved in my_awesome_model_new/checkpoint-13/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_model_new/checkpoint-13/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_model_new/checkpoint-13/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from my_awesome_model_new/checkpoint-13 (score: 1.0333997011184692).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=1.0456160765427809, metrics={'train_runtime': 9.8473, 'train_samples_per_second': 1.32, 'train_steps_per_second': 1.32, 'total_flos': 282274432182.0, 'train_loss': 1.0456160765427809, 'epoch': 1.0})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model_new\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=df_ccase_tokenised,\n",
    "    eval_dataset=df_ccase_tokenised,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "## Note that the train/eval datasets are the same - this is a dummy to be refined\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make this a dictionary\n",
    "\n",
    "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [{'S': 'Jessica speaks to Jessica about how she got her iPad back online'},\n",
    " {'S': 'Jessica says her iPad is connected automatically through WiFi Jessica: \"I think Google stuff again'},\n",
    " {'S': \"This is amazing I think Google things again That's great to hear\"},\n",
    " {'S': 'Is there anything else I can help you with today? Nope'},\n",
    " {'S': 'Could I ask how satisfied you were with a resolution today? Very satisfied Very satisfied, very satisfied'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = '. '.join(a[\"S\"] for a in input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jessica speaks to Jessica about how she got her iPad back online. Jessica says her iPad is connected automatically through WiFi Jessica: \"I think Google stuff again. This is amazing I think Google things again That\\'s great to hear. Is there anything else I can help you with today? Nope. Could I ask how satisfied you were with a resolution today? Very satisfied Very satisfied, very satisfied'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/root/nlp-coe/nlp_models/models/Text Classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-c30ec682e60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyphrases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "output = '. '.join(a['S'] for a in d['M']['data']['M']['keyphrases']['L'][0]['L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file my_awesome_model_new/checkpoint-13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"my_awesome_model_new/checkpoint-13\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"No further operation needed.\",\n",
      "    \"1\": \"Offer a promotion to the customer.\",\n",
      "    \"2\": \"Apply a discount to the price.\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"Apply a discount to the price.\": 2,\n",
      "    \"No further operation needed.\": 0,\n",
      "    \"Offer a promotion to the customer.\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file my_awesome_model_new/checkpoint-13/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"my_awesome_model_new/checkpoint-13\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"No further operation needed.\",\n",
      "    \"1\": \"Offer a promotion to the customer.\",\n",
      "    \"2\": \"Apply a discount to the price.\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"Apply a discount to the price.\": 2,\n",
      "    \"No further operation needed.\": 0,\n",
      "    \"Offer a promotion to the customer.\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file my_awesome_model_new/checkpoint-13/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at my_awesome_model_new/checkpoint-13.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'Apply a discount to the price.', 'score': 0.3546299338340759}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"my_awesome_model_new/checkpoint-13\")\n",
    "classifier(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd \"my_awesome_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/root/nlp-coe/nlp_models/models/Text Classification/my_awesome_model_new/checkpoint-13/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t   scheduler.pt\t\t    trainer_state.json\n",
      "optimizer.pt\t   special_tokens_map.json  training_args.bin\n",
      "pytorch_model.bin  tokenizer.json\t    vocab.txt\n",
      "rng_state.pth\t   tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "optimizer.pt\n",
      "pytorch_model.bin\n",
      "rng_state.pth\n",
      "scheduler.pt\n",
      "special_tokens_map.json\n",
      "tokenizer.json\n",
      "tokenizer_config.json\n",
      "trainer_state.json\n",
      "training_args.bin\n",
      "vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model.tar.gz to s3://aws-nlp-coe/models/ccase_models/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp model.tar.gz s3://aws-nlp-coe/models/ccase_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://aws-nlp-coe/models/ccase_models/model.tar.gz\",  # path to your trained SageMaker model\n",
    "   role=role,                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.17.0\",                           # Transformers version used\n",
    "   pytorch_version=\"1.10.2\",                                # PyTorch version used\n",
    "   py_version='py38',                                    # Python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.model.ModelPackage at 0x7f6d059df550>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.huggingface.model.HuggingFaceModel at 0x7f6d05af7e90>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model.create(instance_type='ml.g4dn.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g4dn.xlarge\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jessica speaks to Jessica about how she got her iPad back online. Jessica says her iPad is connected automatically through WiFi Jessica: \"I think Google stuff again. This is amazing I think Google things again That\\'s great to hear. Is there anything else I can help you with today? Nope. Could I ask how satisfied you were with a resolution today? Very satisfied Very satisfied, very satisfied'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': 'Jessica speaks to Jessica about how she got her iPad back online. Jessica says her iPad is connected automatically through WiFi Jessica: \"I think Google stuff again. This is amazing I think Google things again That\\'s great to hear. Is there anything else I can help you with today? Nope. Could I ask how satisfied you were with a resolution today? Very satisfied Very satisfied, very satisfied'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = {\"inputs\": processed_text}\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3://aws-nlp-coe/models/ccase_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.huggingface.model.HuggingFaceModel at 0x7f6d05af7e90>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = huggingface_model.transformer(instance_count = 1, instance_type = 'ml.g4dn.xlarge', strategy='SingleRecord'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketsess = sagemaker.Session()\n",
    "role=sagemaker.get_execution_role()\n",
    "sagemaker_session_bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-eu-west-1-866647877267'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\u001b[34mWarning: MMS is using non-default JVM parameters: -XX:-UseContainerSupport\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,291 [INFO ] main com.amazonaws.ml.mms.ModelServer - \u001b[0m\n",
      "\u001b[34mMMS Home: /opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 1\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 3499 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.8\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-mms.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/mms/models\u001b[0m\n",
      "\u001b[34mInitial Models: ALL\u001b[0m\n",
      "\u001b[34mLog dir: null\u001b[0m\n",
      "\u001b[34mMetrics dir: null\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 1\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPreload model: false\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,366 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,451 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /home/model-server/tmp/.mms.sock.9000 --handler sagemaker_huggingface_inference_toolkit.handler_service --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /home/model-server/tmp\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,452 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,452 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 39\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,452 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,453 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.8.10\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,453 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,458 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,467 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,533 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,535 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:42,544 [WARN ] pool-3-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,405 [INFO ] pool-2-thread-3 ACCESS_LOG - /169.254.255.130:55322 \"GET /ping HTTP/1.1\" 200 9\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,423 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:55336 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,450 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000014-00000000-f7a35673ffc3b4eb-8d7e5778\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,452 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2842\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,454 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,663 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 124\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,664 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Preprocess time - 0.03147125244140625 ms\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,664 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Predict time - 122.2221851348877 ms\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,664 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Postprocess time - 0.04649162292480469 ms\u001b[0m\n",
      "\u001b[34m2023-02-13T17:12:45,665 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:55346 \"POST /invocations HTTP/1.1\" 200 128\u001b[0m\n",
      "\u001b[32m2023-02-13T17:12:45.445:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_job.transform(data='s3://aws-nlp-coe/models/ccase_models/input.jsonl', content_type='application/json', split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-107-8699d61fefa9>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-107-8699d61fefa9>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    instance_count=1,\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# create transformer to run a batch job\n",
    "batch_job = huggingface_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    strategy='SingleRecord'\n",
    ")\n",
    "\n",
    "# starts batch transform job and uses S3 data as input\n",
    "batch_job.transform(\n",
    "    data='s3://aws-nlp-coe/models/ccase_models/input.jsonl',\n",
    "    content_type='application/json',    \n",
    "    split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "\"inputs\": {\n",
    "\t\"question\": \"What is used for inference?\",\n",
    "\t\"context\": \"My Name is Philipp and I live in Nuremberg. This model is used with sagemaker for inference.\"\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.26.1'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://models/my-bert-model/model.tar.gz\",  # path to your trained SageMaker model\n",
    "   role=role,                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.6\",                           # Transformers version used\n",
    "   pytorch_version=\"1.7\",                                # PyTorch version used\n",
    "   py_version='py36',                                    # Python version used\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
